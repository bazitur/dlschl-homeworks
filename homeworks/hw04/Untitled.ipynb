{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, w, b):\n",
    "        \"\"\"\n",
    "        :param w: вектор весов\n",
    "        :param b: bias\n",
    "        \"\"\"\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def _activate(self, x):\n",
    "        return x > 0\n",
    "     \n",
    "    def forward_pass(self, x):\n",
    "        print(\"Called forward-pass with arg:\", x)\n",
    "        return int(self._activate( np.sum( self.w * x ) + self.b ))\n",
    "    \n",
    "    # The same as backward\n",
    "    def grad_step(self, y_hat, x, y, rate):\n",
    "        print(\"called grad-step with:\", x, y, y_hat)\n",
    "        b_grad = np.sum(y_hat - y)\n",
    "        w_grad = b_grad * x\n",
    "       \n",
    "        \n",
    "        self.w -= rate * w_grad\n",
    "        self.b -= b_grad * rate\n",
    "        \n",
    "        \n",
    "    def loss(self, y_hat, y):\n",
    "        print(\"loss func of\", y, y_hat)\n",
    "        return np.sum(np.square(y_hat - y)) / float(( 2 * len(y)))\n",
    "    \n",
    "    \n",
    "    def fit(self, x, y, rate=0.0001, epochs=100):\n",
    "        print(\"Fitting\", x, \"and\", y)\n",
    "        loss = []\n",
    "        for i in tqdm(range(epochs)):\n",
    "            y_hat_g = []\n",
    "            for x_i, y_i in zip(x, y):\n",
    "                y_hat = self.forward_pass(x_i)\n",
    "                y_hat_g.append(y_hat)\n",
    "                self.grad_step(y_hat, x_i, y_i, rate)\n",
    "            loss.append(self.loss(y_hat_g, y))\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called forward-pass with arg: [ 1.  3.]\n",
      "Called forward-pass with arg: [ 2.  4.]\n",
      "Called forward-pass with arg: [-1.  -3.2]\n",
      "y_pred = [1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([1., 2.])\n",
    "b = 2.\n",
    "X = np.dstack([[1., 2., -1.], [3., 4., -3.2]])[0]\n",
    "\n",
    "\n",
    "perceptron = Perceptron(w, b)\n",
    "y_pred = [perceptron.forward_pass(i) for i in X]\n",
    "print (\"y_pred = \" + str(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called grad-step with: [ 1.  3.] [1] [1, 1, 0]\n",
      "called grad-step with: [ 2.  4.] [0] [1, 1, 0]\n",
      "called grad-step with: [-1.  -3.2] [1] [1, 1, 0]\n",
      "w = [ 0.98   1.959]\n",
      "b = 2.0\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1, 0, 1]).reshape(3, 1)\n",
    "for i in range(len(y)):\n",
    "    perceptron.grad_step(y_pred, X[i], y[i], rate=0.005)\n",
    "\n",
    "print (\"w = \" + str(perceptron.w))\n",
    "print (\"b = \" + str(perceptron.b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
